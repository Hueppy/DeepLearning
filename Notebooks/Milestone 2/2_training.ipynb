{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd18a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:34:00.592219: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b49118e",
   "metadata": {},
   "source": [
    "### Prepare Datasets\n",
    "\n",
    " * Load train dataset and split into train and validation sets\n",
    " * Load test dataset\n",
    " * (Augment train dataset using randomized image manipulation) **INACTIVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05efccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22555 files belonging to 25 classes.\n",
      "Using 20300 files for training.\n",
      "Using 2255 files for validation.\n",
      "Found 2500 files belonging to 25 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:34:02.363898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.367453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.367606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.368194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.368334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.368458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.841569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.841742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.841873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 22:34:02.841992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4130 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:0b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train, validation = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../Dataset/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(224,224),\n",
    "    seed=815,\n",
    "    validation_split=0.1,\n",
    "    subset='both'\n",
    ")\n",
    "\n",
    "test = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../Dataset/test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(224,224)\n",
    ")\n",
    "\n",
    "def prepare(dataset):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.RandomRotation(0.2),\n",
    "        tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
    "        tf.keras.layers.RandomZoom(0.2),\n",
    "    ])\n",
    "\n",
    "    augmented = dataset\n",
    "    for _ in range(4):\n",
    "        augmented = augmented.concatenate(\n",
    "            dataset.map(\n",
    "                lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return augmented.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "#train = prepare(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb6195",
   "metadata": {},
   "source": [
    "### Create model\n",
    " * Instantiate base model (MobileNetV3Small) using ImageNet weights\n",
    " * Freeze layers of base model\n",
    " * Create new sequential model\n",
    "   * First layer is base model\n",
    "   * Following layers are dense with\n",
    "     1. 128 Units, ReLU-Activation and L1L2 regularizer\n",
    "     2. 128 Units, ReLU-Activation and L1L2 regularizer\n",
    "     3. 25 Units, Softmax-Activation and L1L2 regularizer (output)\n",
    " * Compile model with adam optimizer\n",
    "   * Use exponential learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75452c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3small (Functiona  (None, 7, 7, 576)        939120    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28224)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3612800   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,571,657\n",
      "Trainable params: 3,632,537\n",
      "Non-trainable params: 939,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generate_model():\n",
    "    base = tf.keras.applications.MobileNetV3Small(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling=None\n",
    "    )\n",
    "    \n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(base)\n",
    "\n",
    "    regularizer = tf.keras.regularizers.L1L2(\n",
    "        l1=0.00001,\n",
    "        l2=0.005,\n",
    "    )\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizer))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizer))\n",
    "    model.add(tf.keras.layers.Dense(25, activation='softmax', kernel_regularizer=regularizer))\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.001, \n",
    "        decay_steps=250, \n",
    "        decay_rate=0.9\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = generate_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe672298",
   "metadata": {},
   "source": [
    "### Transfer learning\n",
    "\n",
    "Use train and validation dataset to fit dense layers to new dataset. Output data to TensorBoard and Checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e1c214",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:34:04.078833: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [20300]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-10 22:34:04.079074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [20300]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5561: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-05-10 22:34:06.382660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-10 22:34:07.322010: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f58d5902b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-10 22:34:07.322035: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-05-10 22:34:07.325253: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-10 22:34:07.418496: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - ETA: 0s - loss: 2.7479 - accuracy: 0.6770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:34:19.144398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2255]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-10 22:34:19.144738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2255]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 26s 36ms/step - loss: 2.7479 - accuracy: 0.6770 - val_loss: 1.9048 - val_accuracy: 0.7774\n",
      "Epoch 2/25\n",
      "634/635 [============================>.] - ETA: 0s - loss: 1.4281 - accuracy: 0.8561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 1.4279 - accuracy: 0.8561 - val_loss: 1.4603 - val_accuracy: 0.8040\n",
      "Epoch 3/25\n",
      "633/635 [============================>.] - ETA: 0s - loss: 1.0285 - accuracy: 0.9087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 1.0282 - accuracy: 0.9086 - val_loss: 1.3102 - val_accuracy: 0.8115\n",
      "Epoch 4/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.8186 - accuracy: 0.9401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.8184 - accuracy: 0.9401 - val_loss: 1.1474 - val_accuracy: 0.8248\n",
      "Epoch 5/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.6470 - accuracy: 0.9647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 22s 34ms/step - loss: 0.6469 - accuracy: 0.9648 - val_loss: 1.0114 - val_accuracy: 0.8302\n",
      "Epoch 6/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.9780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.5347 - accuracy: 0.9780 - val_loss: 0.9325 - val_accuracy: 0.8497\n",
      "Epoch 7/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.4449 - accuracy: 0.9888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.4448 - accuracy: 0.9888 - val_loss: 0.8618 - val_accuracy: 0.8448\n",
      "Epoch 8/25\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.9932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.3888 - accuracy: 0.9933 - val_loss: 0.8113 - val_accuracy: 0.8559\n",
      "Epoch 9/25\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.9952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.3512 - accuracy: 0.9951 - val_loss: 0.7926 - val_accuracy: 0.8452\n",
      "Epoch 10/25\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.9959"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.3265 - accuracy: 0.9959 - val_loss: 0.7666 - val_accuracy: 0.8523\n",
      "Epoch 11/25\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.9965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.3097 - accuracy: 0.9966 - val_loss: 0.7490 - val_accuracy: 0.8554\n",
      "Epoch 12/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2961 - accuracy: 0.9968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.2960 - accuracy: 0.9968 - val_loss: 0.7418 - val_accuracy: 0.8581\n",
      "Epoch 13/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.9972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2866 - accuracy: 0.9971 - val_loss: 0.7326 - val_accuracy: 0.8585\n",
      "Epoch 14/25\n",
      "635/635 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.9974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2795 - accuracy: 0.9974 - val_loss: 0.7280 - val_accuracy: 0.8585\n",
      "Epoch 15/25\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2736 - accuracy: 0.9979 - val_loss: 0.7219 - val_accuracy: 0.8590\n",
      "Epoch 16/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.2693 - accuracy: 0.9979 - val_loss: 0.7175 - val_accuracy: 0.8590\n",
      "Epoch 17/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2659 - accuracy: 0.9983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.2659 - accuracy: 0.9983 - val_loss: 0.7142 - val_accuracy: 0.8590\n",
      "Epoch 18/25\n",
      "635/635 [==============================] - ETA: 0s - loss: 0.2633 - accuracy: 0.9984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2633 - accuracy: 0.9984 - val_loss: 0.7117 - val_accuracy: 0.8594\n",
      "Epoch 19/25\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.9985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2613 - accuracy: 0.9985 - val_loss: 0.7086 - val_accuracy: 0.8594\n",
      "Epoch 20/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2598 - accuracy: 0.9988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2597 - accuracy: 0.9988 - val_loss: 0.7059 - val_accuracy: 0.8608\n",
      "Epoch 21/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2585 - accuracy: 0.9989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2586 - accuracy: 0.9989 - val_loss: 0.7045 - val_accuracy: 0.8599\n",
      "Epoch 22/25\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.9990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.2576 - accuracy: 0.9990 - val_loss: 0.7028 - val_accuracy: 0.8581\n",
      "Epoch 23/25\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.2569 - accuracy: 0.9991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2569 - accuracy: 0.9991 - val_loss: 0.7015 - val_accuracy: 0.8568\n",
      "Epoch 24/25\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.2564 - accuracy: 0.9991 - val_loss: 0.7006 - val_accuracy: 0.8568\n",
      "Epoch 25/25\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.9991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "635/635 [==============================] - 21s 33ms/step - loss: 0.2560 - accuracy: 0.9991 - val_loss: 0.6998 - val_accuracy: 0.8563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5c0e37bb80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'training-final'\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=f'logs/fit/{name}-{now}',\n",
    "    write_steps_per_second=True\n",
    ")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f'checkpoints/{name}-{now}',\n",
    "    monitor='val_accuracy',\n",
    ")\n",
    "    \n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=validation,\n",
    "    epochs=25, \n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        checkpoint_callback,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12926e36",
   "metadata": {},
   "source": [
    "### Fine tuning\n",
    "\n",
    " * Unfreeze layers of base model\n",
    " * Recompile model using adam optimizer and small static learning rate\n",
    " * Fit model to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75689094",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5561: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 24s 34ms/step - loss: 0.2679 - accuracy: 0.9978 - val_loss: 0.7108 - val_accuracy: 0.8590\n",
      "Epoch 2/10\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2636 - accuracy: 0.9975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2636 - accuracy: 0.9975 - val_loss: 0.7090 - val_accuracy: 0.8599\n",
      "Epoch 3/10\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2626 - accuracy: 0.9974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2627 - accuracy: 0.9974 - val_loss: 0.7122 - val_accuracy: 0.8603\n",
      "Epoch 4/10\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.9976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2614 - accuracy: 0.9975 - val_loss: 0.7088 - val_accuracy: 0.8608\n",
      "Epoch 5/10\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.2601 - accuracy: 0.9978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2601 - accuracy: 0.9978 - val_loss: 0.7071 - val_accuracy: 0.8576\n",
      "Epoch 6/10\n",
      "635/635 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.9973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 22s 34ms/step - loss: 0.2592 - accuracy: 0.9973 - val_loss: 0.7059 - val_accuracy: 0.8612\n",
      "Epoch 7/10\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.2579 - accuracy: 0.9977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 33ms/step - loss: 0.2579 - accuracy: 0.9977 - val_loss: 0.7071 - val_accuracy: 0.8612\n",
      "Epoch 8/10\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2570 - accuracy: 0.9974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 22s 34ms/step - loss: 0.2570 - accuracy: 0.9974 - val_loss: 0.7058 - val_accuracy: 0.8576\n",
      "Epoch 9/10\n",
      "633/635 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 21s 34ms/step - loss: 0.2558 - accuracy: 0.9976 - val_loss: 0.7073 - val_accuracy: 0.8581\n",
      "Epoch 10/10\n",
      "632/635 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/training-final-tune-20230510-223404/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "635/635 [==============================] - 22s 34ms/step - loss: 0.2549 - accuracy: 0.9974 - val_loss: 0.7051 - val_accuracy: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5bd85f2040>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers[0].layers:\n",
    "    layer.Trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.000025),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f'checkpoints/{name}-tune-{now}',\n",
    "    monitor='val_accuracy',\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=validation,\n",
    "    epochs=10, \n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        checkpoint_callback,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4275b",
   "metadata": {},
   "source": [
    "### Evaluate model\n",
    "\n",
    "Use test dataset to evaluate final performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c457e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/79 [=>............................] - ETA: 1s - loss: 0.8680 - accuracy: 0.8393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:46:40.138605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2500]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-10 22:46:40.138932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2500]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 22ms/step - loss: 0.9514 - accuracy: 0.8144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9513553977012634, 0.8144000172615051]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=f'logs/evaluate/{name}-tune-{now}',\n",
    "    write_steps_per_second=True\n",
    ")\n",
    "\n",
    "model.evaluate(\n",
    "    test,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48f6770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "apple;0.78\n",
      "apricot;0.9\n",
      "avocado;0.84\n",
      "banana;0.9\n",
      "bell pepper;0.88\n",
      "black berry;0.93\n",
      "blueberry;0.94\n",
      "cantaloupe;0.89\n",
      "cherry;0.77\n",
      "clementine;0.23\n",
      "eggplant;0.96\n",
      "grape;0.78\n",
      "grapefruit;0.49\n",
      "kiwi;0.97\n",
      "lemon;0.73\n",
      "lime;0.9\n",
      "mandarine;0.83\n",
      "nectarine;0.51\n",
      "orange;0.62\n",
      "pear;0.79\n",
      "pineapple;0.98\n",
      "pomegranate;0.86\n",
      "raspberry;0.96\n",
      "strawberry;0.96\n",
      "watermelon;0.96\n"
     ]
    }
   ],
   "source": [
    "class_names = test.class_names\n",
    "\n",
    "correct_predictions = dict.fromkeys(class_names, 0)\n",
    "for images, labels in test:\n",
    "    predictions = model.predict(images)\n",
    "    for i in range(len(predictions)):\n",
    "        label_class = np.argmax(labels[i])\n",
    "        prediction_class = np.argmax(predictions[i])\n",
    "    \n",
    "        if label_class == prediction_class:\n",
    "            correct_predictions[class_names[label_class]] += 1\n",
    "        \n",
    "for k in correct_predictions:\n",
    "    print(f'{k};{correct_predictions[k] / 100}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8e090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
