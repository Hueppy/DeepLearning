{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fed134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 08:43:13.408206: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7d0ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22555 files belonging to 25 classes.\n",
      "Using 20300 files for training.\n",
      "Using 2255 files for validation.\n",
      "Found 2500 files belonging to 25 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 08:43:15.275116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.278655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.278809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.279401: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.279540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.279664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.761885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.762059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.762190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-10 08:43:15.762310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4130 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:0b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train, validation = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../Dataset/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(224,224),\n",
    "    seed=815,\n",
    "    validation_split=0.1,\n",
    "    subset='both'\n",
    ")\n",
    "\n",
    "test = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../Dataset/test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(224,224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2326cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(name, base):\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(base)\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(25, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return name, model\n",
    "\n",
    "model_factories = [\n",
    "    #lambda: generate_model(\n",
    "    #    \"DenseNet201\",\n",
    "    #    tf.keras.applications.densenet.DenseNet201(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #   )\n",
    "    #),\n",
    "    lambda: generate_model(\n",
    "        \"EfficientNetB4\",\n",
    "        tf.keras.applications.efficientnet.EfficientNetB4(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "       )\n",
    "    ),\n",
    "    lambda: generate_model(\n",
    "        \"EfficientNetV2M\",\n",
    "        tf.keras.applications.efficientnet_v2.EfficientNetV2M(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "       )\n",
    "    ),\n",
    "    #lambda: generate_model(\n",
    "    #    \"InceptionResNetV2\",\n",
    "    #    tf.keras.applications.inception_resnet_v2.InceptionResNetV2(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "    #lambda: generate_model(\n",
    "    #    \"InceptionV3\",\n",
    "    #    tf.keras.applications.inception_v3.InceptionV3(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "    #lambda: generate_model(\n",
    "    #    \"MobileNetV2\",\n",
    "    #    tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "    lambda: generate_model(\n",
    "        \"MobileNetV3Small\",\n",
    "        tf.keras.applications.MobileNetV3Small(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "        )\n",
    "    ),\n",
    "    lambda: generate_model(\n",
    "        \"MobileNetV3Large\",\n",
    "        tf.keras.applications.MobileNetV3Large(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "        )\n",
    "    ),\n",
    "    #lambda: generate_model(\n",
    "    #    \"NASNetMobile\",\n",
    "    #    tf.keras.applications.nasnet.NASNetMobile(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "    #lambda: generate_model(\n",
    "    #    \"ResNet101\",\n",
    "    #    tf.keras.applications.resnet.ResNet101(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "    lambda: generate_model(\n",
    "        \"ResNet152\",\n",
    "        tf.keras.applications.resnet.ResNet152(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "        )\n",
    "    ),\n",
    "    lambda: generate_model(\n",
    "        \"ResNet50\",\n",
    "        tf.keras.applications.resnet50.ResNet50(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "        )\n",
    "    ),\n",
    "    lambda: generate_model(\n",
    "        \"ResNetRS101\",\n",
    "        tf.keras.applications.resnet_rs.ResNetRS101(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "        )\n",
    "    ),\n",
    "    lambda: generate_model(\n",
    "        \"ResNetRS152\",\n",
    "        tf.keras.applications.resnet_rs.ResNetRS152(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "        )\n",
    "    ),\n",
    "    lambda: generate_model(\n",
    "        \"ResNetRS50\",\n",
    "        tf.keras.applications.resnet_rs.ResNetRS50(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "        )\n",
    "    ),\n",
    "    #lambda: generate_model(\n",
    "    #    \"ResNet101V2\",\n",
    "    #    tf.keras.applications.resnet_v2.ResNet101V2(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "    #lambda: generate_model(\n",
    "    #    \"ResNet152V2\",\n",
    "    #    tf.keras.applications.resnet_v2.ResNet152V2(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "    #lambda: generate_model(\n",
    "    #    \"ResNet50V2\",\n",
    "    #    tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "    lambda: generate_model(\n",
    "        \"VGG16\",\n",
    "        tf.keras.applications.vgg16.VGG16(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224,224,3),\n",
    "            pooling=None\n",
    "        )\n",
    "    ),\n",
    "    #lambda: generate_model(\n",
    "    #    \"Xception\",\n",
    "    #    tf.keras.applications.xception.Xception(\n",
    "    #        include_top=False,\n",
    "    #        weights='imagenet',\n",
    "    #        input_shape=(224,224,3),\n",
    "    #        pooling=None\n",
    "    #    )\n",
    "    #),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa1fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training EfficientNetB4:\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 08:43:18.817396: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [20300]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-10 08:43:18.817639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [20300]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5561: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-05-10 08:43:24.339326: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/efficientnetb4/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-05-10 08:43:25.329176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-10 08:43:25.926403: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x3491d980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-10 08:43:25.926427: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-05-10 08:43:25.930278: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-10 08:43:26.052847: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - ETA: 0s - loss: 1.0507 - accuracy: 0.7114"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 08:44:40.063130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2255]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-10 08:44:40.063307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2255]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 92s 133ms/step - loss: 1.0507 - accuracy: 0.7114 - val_loss: 0.6884 - val_accuracy: 0.7956\n",
      "Epoch 2/10\n",
      "635/635 [==============================] - 82s 129ms/step - loss: 0.5197 - accuracy: 0.8419 - val_loss: 0.7467 - val_accuracy: 0.7880\n",
      "Epoch 3/10\n",
      "635/635 [==============================] - 82s 129ms/step - loss: 0.3839 - accuracy: 0.8806 - val_loss: 0.6419 - val_accuracy: 0.8222\n",
      "Epoch 4/10\n",
      "635/635 [==============================] - 82s 130ms/step - loss: 0.2963 - accuracy: 0.9043 - val_loss: 0.7167 - val_accuracy: 0.8195\n",
      "Epoch 5/10\n",
      "635/635 [==============================] - 82s 129ms/step - loss: 0.2608 - accuracy: 0.9169 - val_loss: 0.6338 - val_accuracy: 0.8448\n",
      "Epoch 6/10\n",
      "635/635 [==============================] - 82s 129ms/step - loss: 0.2228 - accuracy: 0.9291 - val_loss: 0.6415 - val_accuracy: 0.8488\n",
      "Epoch 7/10\n",
      "635/635 [==============================] - 82s 129ms/step - loss: 0.1781 - accuracy: 0.9431 - val_loss: 0.7851 - val_accuracy: 0.8293\n",
      "Epoch 8/10\n",
      "635/635 [==============================] - 82s 129ms/step - loss: 0.1993 - accuracy: 0.9394 - val_loss: 0.7848 - val_accuracy: 0.8457\n",
      "Epoch 9/10\n",
      "635/635 [==============================] - 82s 129ms/step - loss: 0.1601 - accuracy: 0.9504 - val_loss: 0.6991 - val_accuracy: 0.8510\n",
      "Epoch 10/10\n",
      "635/635 [==============================] - 82s 129ms/step - loss: 0.1532 - accuracy: 0.9544 - val_loss: 0.7323 - val_accuracy: 0.8470\n",
      "Evaluating EfficientNetB4:\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      " 1/79 [..............................] - ETA: 11s - loss: 1.4695 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 08:57:08.891836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2500]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-10 08:57:08.892102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2500]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 9s 119ms/step - loss: 1.1209 - accuracy: 0.8060\n",
      "Training EfficientNetV2M:\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 08:57:31.303357: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/efficientnetv2-m/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - ETA: 0s - loss: 1.0995 - accuracy: 0.6830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 08:59:17.870270: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 126s 183ms/step - loss: 1.0995 - accuracy: 0.6830 - val_loss: 0.6480 - val_accuracy: 0.7863\n",
      "Epoch 2/10\n",
      "635/635 [==============================] - 113s 177ms/step - loss: 0.5912 - accuracy: 0.8077 - val_loss: 0.5737 - val_accuracy: 0.8195\n",
      "Epoch 3/10\n",
      "635/635 [==============================] - 113s 178ms/step - loss: 0.4881 - accuracy: 0.8451 - val_loss: 0.5922 - val_accuracy: 0.7991\n",
      "Epoch 4/10\n",
      "635/635 [==============================] - 113s 177ms/step - loss: 0.4005 - accuracy: 0.8678 - val_loss: 0.6173 - val_accuracy: 0.8169\n",
      "Epoch 5/10\n",
      "635/635 [==============================] - 113s 178ms/step - loss: 0.3636 - accuracy: 0.8800 - val_loss: 0.5475 - val_accuracy: 0.8381\n",
      "Epoch 6/10\n",
      "635/635 [==============================] - 113s 178ms/step - loss: 0.3198 - accuracy: 0.8951 - val_loss: 0.4930 - val_accuracy: 0.8581\n",
      "Epoch 7/10\n",
      "635/635 [==============================] - 113s 178ms/step - loss: 0.2829 - accuracy: 0.9087 - val_loss: 0.5684 - val_accuracy: 0.8461\n",
      "Epoch 8/10\n",
      "635/635 [==============================] - 113s 177ms/step - loss: 0.2760 - accuracy: 0.9106 - val_loss: 0.5381 - val_accuracy: 0.8550\n",
      "Epoch 9/10\n",
      "635/635 [==============================] - 113s 178ms/step - loss: 0.2397 - accuracy: 0.9193 - val_loss: 0.5502 - val_accuracy: 0.8506\n",
      "Epoch 10/10\n",
      "635/635 [==============================] - 113s 177ms/step - loss: 0.2256 - accuracy: 0.9242 - val_loss: 0.5651 - val_accuracy: 0.8545\n",
      "Evaluating EfficientNetV2M:\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 0.9058 - accuracy: 0.8020\n",
      "Training MobileNetV3Small:\n",
      "Epoch 1/10\n",
      "635/635 [==============================] - 16s 21ms/step - loss: 1.1100 - accuracy: 0.6804 - val_loss: 0.7463 - val_accuracy: 0.7659\n",
      "Epoch 2/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.3771 - accuracy: 0.8767 - val_loss: 0.7882 - val_accuracy: 0.7867\n",
      "Epoch 3/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.2052 - accuracy: 0.9328 - val_loss: 0.8907 - val_accuracy: 0.8004\n",
      "Epoch 4/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.1886 - accuracy: 0.9410 - val_loss: 1.0082 - val_accuracy: 0.8031\n",
      "Epoch 5/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.1626 - accuracy: 0.9501 - val_loss: 1.1737 - val_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.1664 - accuracy: 0.9526 - val_loss: 1.1738 - val_accuracy: 0.7929\n",
      "Epoch 7/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.1253 - accuracy: 0.9660 - val_loss: 1.2616 - val_accuracy: 0.7965\n",
      "Epoch 8/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.1068 - accuracy: 0.9698 - val_loss: 1.2946 - val_accuracy: 0.8106\n",
      "Epoch 9/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.1017 - accuracy: 0.9710 - val_loss: 1.3510 - val_accuracy: 0.8071\n",
      "Epoch 10/10\n",
      "635/635 [==============================] - 12s 19ms/step - loss: 0.1007 - accuracy: 0.9731 - val_loss: 1.3464 - val_accuracy: 0.8195\n",
      "Evaluating MobileNetV3Small:\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 2.0466 - accuracy: 0.7720\n",
      "Training MobileNetV3Large:\n",
      "Epoch 1/10\n",
      "635/635 [==============================] - 26s 36ms/step - loss: 0.9804 - accuracy: 0.7369 - val_loss: 0.6947 - val_accuracy: 0.8044\n",
      "Epoch 2/10\n",
      "635/635 [==============================] - 22s 34ms/step - loss: 0.3184 - accuracy: 0.9070 - val_loss: 0.6693 - val_accuracy: 0.8324\n",
      "Epoch 3/10\n",
      "635/635 [==============================] - 22s 34ms/step - loss: 0.1855 - accuracy: 0.9488 - val_loss: 0.9021 - val_accuracy: 0.8271\n",
      "Epoch 4/10\n",
      "635/635 [==============================] - 21s 34ms/step - loss: 0.1587 - accuracy: 0.9583 - val_loss: 0.9314 - val_accuracy: 0.8324\n",
      "Epoch 5/10\n",
      "635/635 [==============================] - 22s 34ms/step - loss: 0.1408 - accuracy: 0.9644 - val_loss: 0.9208 - val_accuracy: 0.8399\n",
      "Epoch 6/10\n",
      "635/635 [==============================] - 22s 34ms/step - loss: 0.1290 - accuracy: 0.9683 - val_loss: 1.0261 - val_accuracy: 0.8443\n",
      "Epoch 7/10\n",
      "635/635 [==============================] - 21s 34ms/step - loss: 0.1038 - accuracy: 0.9752 - val_loss: 1.1249 - val_accuracy: 0.8386\n",
      "Epoch 8/10\n",
      "635/635 [==============================] - 22s 34ms/step - loss: 0.1162 - accuracy: 0.9722 - val_loss: 1.0973 - val_accuracy: 0.8430\n",
      "Epoch 9/10\n",
      "635/635 [==============================] - 21s 34ms/step - loss: 0.1120 - accuracy: 0.9728 - val_loss: 1.2853 - val_accuracy: 0.8355\n",
      "Epoch 10/10\n",
      "635/635 [==============================] - 21s 34ms/step - loss: 0.0800 - accuracy: 0.9805 - val_loss: 1.1952 - val_accuracy: 0.8470\n",
      "Evaluating MobileNetV3Large:\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 1.9720 - accuracy: 0.7860\n",
      "Training ResNet152:\n",
      "Epoch 1/10\n",
      "635/635 [==============================] - 125s 189ms/step - loss: 1.9212 - accuracy: 0.6197 - val_loss: 0.9102 - val_accuracy: 0.7388\n",
      "Epoch 2/10\n",
      "635/635 [==============================] - 118s 185ms/step - loss: 0.6286 - accuracy: 0.8226 - val_loss: 0.9849 - val_accuracy: 0.7659\n",
      "Epoch 3/10\n",
      "414/635 [==================>...........] - ETA: 36s - loss: 0.3724 - accuracy: 0.8930"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "   \n",
    "for factory in model_factories:\n",
    "    name, model = factory()\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=f'logs/fit/selection2-{name}-{now}'\n",
    "    )\n",
    "    \n",
    "    print(f'Training {name}:')\n",
    "    model.fit(\n",
    "        train,\n",
    "        validation_data=validation,\n",
    "        epochs=10, \n",
    "        callbacks=[tensorboard_callback]\n",
    "    )\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=f'logs/evaluate/selection2-{name}-{now}'\n",
    "    )\n",
    "    \n",
    "    print(f'Evaluating {name}:')\n",
    "    model.evaluate(\n",
    "        test, \n",
    "        callbacks=[tensorboard_callback]\n",
    "    )\n",
    "    \n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c6d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
