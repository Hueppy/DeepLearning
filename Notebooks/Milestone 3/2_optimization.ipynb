{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58615c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 02:23:38.196976: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17092600",
   "metadata": {},
   "source": [
    "### Prepare Datasets\n",
    "\n",
    " * Load train dataset and split into train and validation sets\n",
    " * Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26a4815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22573 files belonging to 25 classes.\n",
      "Using 20316 files for training.\n",
      "Using 2257 files for validation.\n",
      "Found 2500 files belonging to 25 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 02:23:40.299683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.303551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.303713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.304322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.304469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.304601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.791240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.791417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.791550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-28 02:23:40.791670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4575 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:0b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train, validation = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../Dataset/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(224,224),\n",
    "    seed=815,\n",
    "    validation_split=0.1,\n",
    "    subset='both'\n",
    ")\n",
    "\n",
    "test = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../Dataset/test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(224,224)\n",
    ")\n",
    "\n",
    "def prepare(dataset):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.RandomRotation(0.2),\n",
    "        tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
    "        tf.keras.layers.RandomZoom(0.2),\n",
    "    ])\n",
    "\n",
    "    augmented = dataset\n",
    "    for _ in range(4):\n",
    "        augmented = augmented.concatenate(\n",
    "            dataset.map(\n",
    "                lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return augmented.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train = prepare(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e1b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('models'):\n",
    "    os.mkdir('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a2058",
   "metadata": {},
   "source": [
    "### Create model\n",
    " * Convolutional block\n",
    "   * Residual \"skipping\" layer\n",
    "   * Batch normalization around each convolutional layer\n",
    "   * (2,2) Max Pooling with stride (2,2) after all convulutional layers\n",
    " * Flatten\n",
    " * Dense layers with ReLu activation\n",
    " * Output layer with Softmax activation\n",
    " * Model compiled with adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7976126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(conv_layers, dense_layers):    \n",
    "    img_input = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "    x = tf.keras.layers.BatchNormalization()(img_input)\n",
    "    \n",
    "    for filters, kernel_size, depth, pool in conv_layers:\n",
    "        shortcut = tf.keras.layers.Conv2D(filters, 1, activation='relu')(x)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "        \n",
    "        for i in range(depth):\n",
    "            x = tf.keras.layers.Conv2D(                \n",
    "                filters,\n",
    "                kernel_size,\n",
    "                activation='relu',\n",
    "                padding='same'\n",
    "            )(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "                \n",
    "        x = tf.keras.layers.Add()([shortcut,x])\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "            \n",
    "        if pool > 1:\n",
    "            x = tf.keras.layers.MaxPool2D(\n",
    "                pool_size=pool\n",
    "            )(x)\n",
    "            \n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    for units in dense_layers:\n",
    "        x = tf.keras.layers.Dense(\n",
    "            units,\n",
    "            activation='relu'\n",
    "        )(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(\n",
    "        25,\n",
    "        activation='softmax'\n",
    "    )(x)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(img_input, x)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652d9ee",
   "metadata": {},
   "source": [
    "### Run \n",
    "\n",
    " * Instantiate model with set parameters\n",
    " * Save model json to file\n",
    " * Fit model to training dataset\n",
    "   * Early stopping callback\n",
    "   * TensorBoard callback\n",
    "   * Model checkpoint callback\n",
    " * Evaluate model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297aa8ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 224, 224, 3)  12         ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 224, 224, 32  896         ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 224, 32  128        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 224, 224, 32  128         ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 224, 224, 32  9248        ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 224, 224, 32  128        ['conv2d[0][0]']                 \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 224, 224, 32  128        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 224, 224, 32  0           ['batch_normalization_1[0][0]',  \n",
      "                                )                                 'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 224, 224, 32  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 32  0           ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 112, 112, 32  128        ['max_pooling2d[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 112, 112, 64  51264       ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 112, 112, 64  256        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 112, 112, 64  2112        ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 112, 112, 64  102464      ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 112, 112, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 112, 112, 64  256        ['conv2d_5[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 112, 112, 64  0           ['batch_normalization_5[0][0]',  \n",
      "                                )                                 'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 112, 112, 64  0           ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)  0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 56, 56, 64)  256         ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 56, 56, 128)  401536      ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 56, 56, 128)  512        ['conv2d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 56, 56, 128)  8320        ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 56, 56, 128)  802944      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 56, 56, 128)  512        ['conv2d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_2 (Add)                    (None, 56, 56, 128)  0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 56, 56, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 128)  0          ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 28, 28, 128)  512        ['max_pooling2d_2[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 100352)       0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          12845184    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 192)          24768       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 25)           4825        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,257,285\n",
      "Trainable params: 14,255,487\n",
      "Non-trainable params: 1,798\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 02:23:41.931296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_49' with dtype int32 and shape [20316]\n",
      "\t [[{{node Placeholder/_49}}]]\n",
      "2023-05-28 02:23:41.932093: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_119' with dtype resource\n",
      "\t [[{{node Placeholder/_119}}]]\n",
      "2023-05-28 02:23:44.154928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-28 02:23:46.919971: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fb8e1096900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-28 02:23:46.919995: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-05-28 02:23:46.923108: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-28 02:23:47.017289: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175/3175 [==============================] - ETA: 0s - loss: 2.5813 - accuracy: 0.2380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 02:34:07.684008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2257]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-28 02:34:07.684188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2257]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/20230528-022341-0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/20230528-022341-0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175/3175 [==============================] - 634s 196ms/step - loss: 2.5813 - accuracy: 0.2380 - val_loss: 2.1394 - val_accuracy: 0.3447\n",
      "Epoch 2/25\n",
      "3175/3175 [==============================] - ETA: 0s - loss: 1.8322 - accuracy: 0.4188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/20230528-022341-0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/20230528-022341-0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175/3175 [==============================] - 615s 194ms/step - loss: 1.8322 - accuracy: 0.4188 - val_loss: 1.7634 - val_accuracy: 0.4807\n",
      "Epoch 3/25\n",
      "3175/3175 [==============================] - ETA: 0s - loss: 1.5140 - accuracy: 0.5184"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/20230528-022341-0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/20230528-022341-0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175/3175 [==============================] - 615s 194ms/step - loss: 1.5140 - accuracy: 0.5184 - val_loss: 1.5706 - val_accuracy: 0.5277\n",
      "Epoch 4/25\n",
      " 221/3175 [=>............................] - ETA: 9:22 - loss: 1.1523 - accuracy: 0.6322"
     ]
    }
   ],
   "source": [
    "def run(id):\n",
    "    model = generate_model(\n",
    "        [\n",
    "            # filters, kernel_size, depth, pool\n",
    "            (32, 3, 2, 2),\n",
    "            (64, 5, 2, 2),\n",
    "            (128, 7, 2, 2),\n",
    "        ], \n",
    "        [\n",
    "            # units\n",
    "            128,\n",
    "            192,\n",
    "        ])\n",
    "    model.summary()\n",
    "    \n",
    "    with open(f'models/{id}.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "        \n",
    "    model.fit(\n",
    "        train,\n",
    "        validation_data=validation,\n",
    "        epochs=25, \n",
    "        #batch_size=16,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(),\n",
    "            tf.keras.callbacks.TensorBoard(\n",
    "                log_dir=f'logs/fit/{id}'\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=f'checkpoints/{id}',\n",
    "                monitor='val_accuracy',\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    model.evaluate(\n",
    "        test, \n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.TensorBoard(\n",
    "                log_dir=f'logs/evaluate/{id}'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "for i in range(10):\n",
    "    run(f'{now}-{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746ce01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477c7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
