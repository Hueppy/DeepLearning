{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58615c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 22:33:16.228617: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26a4815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22573 files belonging to 25 classes.\n",
      "Using 20316 files for training.\n",
      "Using 2257 files for validation.\n",
      "Found 2500 files belonging to 25 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 22:33:17.972649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:17.977095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:17.977259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:17.977861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:17.978013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:17.978149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:18.474490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:18.474665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:18.474798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 22:33:18.474919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4575 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:0b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train, validation = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../Dataset/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(224,224),\n",
    "    seed=815,\n",
    "    validation_split=0.1,\n",
    "    subset='both'\n",
    ")\n",
    "\n",
    "test = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../Dataset/test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(224,224)\n",
    ")\n",
    "\n",
    "def prepare(dataset):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.RandomRotation(0.5),\n",
    "        tf.keras.layers.RandomTranslation(0.33, 0.33),\n",
    "        tf.keras.layers.RandomZoom(0.33),\n",
    "    ])\n",
    "\n",
    "    augmented = dataset\n",
    "    for _ in range(99):\n",
    "        augmented = augmented.concatenate(\n",
    "            dataset.map(\n",
    "                lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return augmented.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train = prepare(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e1b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('models'):\n",
    "    os.mkdir('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7976126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(conv_layers, dense_layers):    \n",
    "    img_input = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "    x = tf.keras.layers.BatchNormalization()(img_input)\n",
    "    \n",
    "    for filters, kernel_size, depth, pool in conv_layers:\n",
    "        shortcut = tf.keras.layers.Conv2D(filters, 1, activation='relu')(x)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "        \n",
    "        for i in range(depth):\n",
    "            x = tf.keras.layers.Conv2D(                \n",
    "                filters,\n",
    "                kernel_size,\n",
    "                activation='relu',\n",
    "                padding='same'\n",
    "            )(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "                \n",
    "        x = tf.keras.layers.Add()([shortcut,x])\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "            \n",
    "        if pool > 1:\n",
    "            x = tf.keras.layers.MaxPool2D(\n",
    "                pool_size=pool\n",
    "            )(x)\n",
    "            \n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    for units in dense_layers:\n",
    "        x = tf.keras.layers.Dense(\n",
    "            units,\n",
    "            activation='relu'\n",
    "        )(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(\n",
    "        25,\n",
    "        activation='softmax'\n",
    "    )(x)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(img_input, x)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297aa8ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 224, 224, 3)  12         ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 224, 224, 32  4736        ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 224, 32  128        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 224, 224, 32  128         ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 224, 224, 32  50208       ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 224, 224, 32  128        ['conv2d[0][0]']                 \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 224, 224, 32  128        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 224, 224, 32  0           ['batch_normalization_1[0][0]',  \n",
      "                                )                                 'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 224, 224, 32  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 32  0           ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 112, 112, 32  128        ['max_pooling2d[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 112, 112, 64  51264       ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 112, 112, 64  256        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 112, 112, 64  102464      ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 112, 112, 64  256        ['conv2d_5[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 112, 112, 64  2112        ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 112, 112, 64  102464      ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 112, 112, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 112, 112, 64  256        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 112, 112, 64  0           ['batch_normalization_5[0][0]',  \n",
      "                                )                                 'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 112, 112, 64  0           ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)  0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 56, 56, 64)  256         ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 56, 56, 128)  73856       ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 56, 56, 128)  512        ['conv2d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 56, 56, 128)  147584      ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 56, 56, 128)  512        ['conv2d_9[0][0]']               \n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 56, 56, 128)  147584      ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 56, 56, 128)  512        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 56, 56, 128)  8320        ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 56, 56, 128)  147584      ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 56, 56, 128)  512        ['conv2d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 56, 56, 128)  512        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 56, 56, 128)  0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 56, 56, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 128)  0          ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 28, 28, 128)  512        ['max_pooling2d_2[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 100352)       0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          12845184    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 192)          24768       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 25)           4825        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,717,957\n",
      "Trainable params: 13,715,519\n",
      "Non-trainable params: 2,438\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 22:33:31.724955: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open checkpoints/20230530-005310: FAILED_PRECONDITION: checkpoints/20230530-005310; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n",
      "2023-05-30 22:33:32.351471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1624' with dtype resource\n",
      "\t [[{{node Placeholder/_1624}}]]\n",
      "2023-05-30 22:33:32.366050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_922' with dtype resource\n",
      "\t [[{{node Placeholder/_922}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 22:33:44.955610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-30 22:33:48.141796: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f89af3d9990 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-30 22:33:48.141821: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-05-30 22:33:48.144829: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-30 22:33:48.237189: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8359/63500 [==>...........................] - ETA: 3:46:10 - loss: 0.4020 - accuracy: 0.8876"
     ]
    }
   ],
   "source": [
    "def run(id):\n",
    "    model = generate_model(\n",
    "        [\n",
    "            # filters, kernel_size, depth, pool\n",
    "            (32, 7, 2, 2),\n",
    "            (64, 5, 3, 2),\n",
    "            (128, 3, 4, 2),\n",
    "        ], \n",
    "        [\n",
    "            # units\n",
    "            128,\n",
    "            192,\n",
    "        ])\n",
    "    model.summary()\n",
    "    \n",
    "    model.load_weights('checkpoints/20230530-005310')\n",
    "        \n",
    "    model.fit(\n",
    "        train,\n",
    "        validation_data=validation,\n",
    "        epochs=5, \n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.TensorBoard(\n",
    "                log_dir=f'logs/fit/{id}'\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=f'checkpoints/{id}',\n",
    "                monitor='val_accuracy',\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    model.evaluate(\n",
    "        test, \n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.TensorBoard(\n",
    "                log_dir=f'logs/evaluate/{id}'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "run(f'{now}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746ce01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477c7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
